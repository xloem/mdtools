The mathematics of RAID-6

H. Peter Anvin <hpa@zytor.com>

First version 20 January 2004
Last updated 20 December 2011

RAID-6 supports losing any two drives. The way this is done is by computing two

syndromes, generally referred P and Q.

1 A quick summary of Galois ﬁeld algebra

The algebra used for this is the algebra of a Galois ﬁeld, GF(28). A smaller or larger ﬁeld
could also be used, however, a smaller ﬁeld would limit the number of drives possible, and
a larger ﬁeld would require extremely large tables.

GF(28) allows for a maximum of 257 drives, 255 (28 − 1) of which can be data drives;

the reason for this is shown below.

The representation of GF(28) is called a cyclic representation. Earlier versions of this pa-
per incorrectly stated that it “is the same one as used by the Rijndael (AES) cryptosystem,”
however, that is not correct.1

It has the following properties; this is not, however, an exhaustive list nor a formal
derivation of these properties; for more in-depth coverage see any textbook on group and
ring theory.

Note: A number in {} is a Galois ﬁeld element (i.e. a byte) in hexadecimal representation;

a number without {} is a conventional integer.

1. The addition ﬁeld operator (+) is represented by bitwise XOR.

2. As a result, addition and subtraction are the same operation: A + B = A − B.

3. The additive identity element (0) is represented by {00}.

4. Thus, A + A = A − A = {00}.

5. Multiplication (·) by {02} is implemented by the following bitwise relations:

(x · {02})7 = x6
(x · {02})6 = x5
(x · {02})5 = x4
(x · {02})4 = x3 + x7
(x · {02})3 = x2 + x7
(x · {02})2 = x1 + x7
(x · {02})1 = x0
(x · {02})0 = x7

1

1{02} is not a generator of the AES representation of GF(28), and as such it is not suitable.

Hardware engineers will recognize this as a linear feedback shift register (LFSR), and
matematicians as boolean polynomial multiplication modulo the irreducible polyno-
mial x8 + x4 + x3 + x2 + 1.

6. The multiplicative identity element (1) is represented by {01}.

A · {01} = {01} · A = A

7. The following basic rules of algebra apply:

Addition is commutative:
Addition is associative:
Multiplication is commutative:
Multiplication is associative:
Distributive law:

A + B = B + A
(A + B) + C = A + (B + C)
A · B = B · A
(A · B) · C = A · (B · C)
(A + B) · C = A · C + B · C

8. For every A (cid:54)= {00}, there exists an element A−1 such that A · A−1 = {01}. A−1 is
called the inverse (or reciprocal) of A. {01} is its own inverse, {00} lacks inverse, for
all other A, A−1 (cid:54)= A.

9. Division is deﬁned as multiplication with an inverse:

A/B = A · B−1

Any nonzero element can uniquely divide any element:

If A · B = C then C/B = A for any B (cid:54)= {00}.
In particular, A/A = A · A−1 = {01} for any A (cid:54)= {00}.

10. Multiplying by zero is zero:

A · {00} = {00}

11. Any value can be multiplied by observing that bits decompose the same as in ordinary

arithmetric, and applying the distributive law:

{02}2 = {02} · {02} = {04}
{02}3 = {04} · {02} = {08}
{02}4 = {08} · {02} = {10}
{02}5 = {10} · {02} = {20}
{02}6 = {20} · {02} = {40}
{02}7 = {40} · {02} = {80}

(Note, however: {02}8 = {1d}.)
For example:

Thus:

or, equivalently,

{8d} = {80} + {08} + {04} + {01}

= {02}7 + {02}3 + {02}2 + {01}

A · {8d} = A · {02}7 + A · {02}3 + A · {02}2 + A

A · {8d} = (((A · {02}4) + A) · {02} + A) · {02}2 + A

2

12. Raising to a power (repeated multiplication with the same value) is congruent mod 255
(cardinality of all elements except {00}). Also note that the exponent is an ordinary
integer modulo 255 (an element in Z255) as opposed to a Galois ﬁeld element.

A256 = {01} · A = A
A255 = {01}
A254 = A255/A = {01}/A = A−1






A (cid:54)= {00}

13. There are elements (g), called generators, of the ﬁeld such that gn doesn’t repeat until
they have exhausted all elements of the ﬁeld except {00}. For the Linux RAID-6 ﬁeld
representation, {02} is such a generator – as is {02}n for any n which is relative prime
to 255.

14. Accordingly, any generator g deﬁnes a function from the nonzero elements in GF(28)
to the elements in Z255 (the integers 0-254 modulo 255) called the logarithm with base
g and written logg. For example, {02}4 = {10}, so log{02} {10} = 4.

15. For any nonzero Galois ﬁeld elements A and B:

A · B = C ⇐⇒ logg A ⊕ logg B = logg C
A/B = C ⇐⇒ logg A (cid:9) logg B = logg C

... where ⊕ and (cid:9) represents conventional integer addition and subtraction modulo
255. Therefore:

A · B = C ⇐⇒ C = g(logg A⊕logg B)
A/B = C ⇐⇒ C = g(logg A(cid:9)logg B)

These relations can be used to do multiplication and division without large tables, as
long as {00} is handled specially.

2 Application to RAID-6

We treat each disk block as a vector of bytes, and will perform the same calculations on
each byte in the vector. Symbols in boldface represent vectors (where each byte has a
diﬀerent value); constants, or symbols in italics represent scalars (same value across every
data byte.)

In order to be able to suﬀer the loss of any two disks, we need to compute two syndromes,

here referred to as P and Q.

For n data disks D0, D1, D2, ... Dn−1 (n ≤ 255) compute:

P = D0 + D1 + D2 + ... + Dn−1
Q = g0 · D0 + g1 · D1 + g2 · D2 + ... + gn−1 · Dn−1

(1)

(2)

where g is any generator of the ﬁeld (we use g = {02}.)
P is the ordinary XOR parity, since “addition” is XOR. Q is referred to as a Reed-

Solomon code.

If we lose one data drive, we can use the normal XOR parity to recover the failed drive
data, just as we would do for RAID-5. If we lose a non-data drive, i.e. P or Q, then we can
just recompute.

3

If we lose one data drive plus the Q drive, we can recalculate the data drive using the

XOR parity, and then recompute the Q drive.

If we lose one data drive plus the P drive, we can recompute the lost data drive (Dx)

from the Q drive by computing Qx as if Dx = {00}, and observing:

Here, x, Q and Qx are known. Since addition and subtraction is the same:

Qx + gx · Dx = Q

gx · Dx = Q + Qx

Dx = (Q + Qx)/gx = (Q + Qx) · g−x

where, per the algebra rules, g−x = g255−x.
If we lose two data drives, Dx and Dy, but still have the P and Q values, we compute

Pxy and Qxy by setting the missing drives to {00}, and we get:

Pxy + Dx + Dy = P
Qxy + gx · Dx + gy · Dy = Q

x, y, P, Pxy, Q and Qxy are known.
Divide the second equation by gx:

g−x · Qxy + Dx + gy−x · Dy = g−x · Q

Remembering that addition equals subtraction in this algebra:

Dx + gy−x · Dy = g−x · Q + g−x · Qxy

Dx = g−x · (Q + Qxy) + gy−x · Dy

Substitute into the ﬁrst equation, solve for Dy:

Dy = P + Pxy + Dx

Dx = g−x · (Q + Qxy) + gy−x · (P + Pxy + Dx)

Dx = g−x · (Q + Qxy) + gy−x · (P + Pxy) + gy−x · Dx

Dx + gy−x · Dx = g−x · (Q + Qxy) + gy−x · (P + Pxy)

(gy−x + {01}) · Dx = g−x · (Q + Qxy) + gy−x · (P + Pxy)

If gy−x + {01} (cid:54)= {00}, we can divide by it. This requires gy−x (cid:54)= {01}; this will
be true as long as y (cid:54)= x, mod 255. Since we can have no more than 255 data disks,
0 ≤ x, y ≤ n − 1 < 255, this implies the only constraint is y (cid:54)= x, which is true by
assumption. Thus, we can divide:

4

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

(15)

Dx =

g−x · (Q + Qxy) + gy−x · (P + Pxy)
gy−x + {01}

For any particular data reconstruction, we can simplify this by precomputing a few

multiplication tables:

A =

B =

gy−x
gy−x + {01}
g−x
gy−x + {01}

= gy−x · (gy−x + {01})−1

= g−x · (gy−x + {01})−1

... which only depend on x and y as opposed to on the data bytes.
The expression then becomes:

Dx = A · (P + Pxy) + B · (Q + Qxy)

We can then get Dy from the previous expression:

Dy = (P + Pxy) + Dx

(16)

(17)

(18)

(19)

(20)

3 Making it go fast

The biggest problem with RAID-6 has historically been the high CPU cost of computing
the Q syndrome. The biggest cost is related to the cost of Galois ﬁeld multiplication, which
doesn’t map conveniently onto standard CPU hardware, and therefore has typically been
done by table lookup.

Table lookups, however, are inherently serializing; it would be desirable to make use of

the wide datapaths of current CPUs.

In order to do this, we factor equation 2 as such:

Q = ((...Dn−1...) · g + D2) · g + D1) · g + D0

(21)

The only operations in this is addition, i.e. XOR, and multiplication by g = {02}. Thus,
we only need an eﬃcient way to implement multiplication by {02} in order to compute Q
quickly, not arbitrary multiplication.

Multiplication by {02} for a single byte can be implemeted using the C code:

uint8_t c, cc;
cc = (c << 1) ^ ((c & 0x80) ? 0x1d : 0);

Now, we want to do this on multiple bytes in parallel. Assume for the moment we are
on a 32-bit machine (the extension to 64 bits should be obvious), and separate these into
two parts:

uint32_t v, vv;

vv = (v << 1) & 0xfefefefe;
vv ^= ((v & 0x00000080) ? 0x0000001d : 0) +
((v & 0x00008000) ? 0x00001d00 : 0) +
((v & 0x00800000) ? 0x001d0000 : 0) +
((v & 0x80000000) ? 0x1d000000 : 0);

5

The 0xfefefefe of the ﬁrst statement masks any bits that get shifted into the next byte.
The second statement is clearly too complex to be eﬃciently executed, however. If we can
produce a mask based on the top bit in each byte, we could just do:

uint32_t v, vv;

vv = (v << 1) & 0xfefefefe;
vv ^= MASK(v) & 0x1d1d1d1d;

uint32_t MASK(uint32_t v)
{

In standard portable C, one implemenation of this MASK() function looks like:

v &= 0x80808080;
return (v << 1) - (v >> 7);

/* Extract the top bits */
/* Overflow on the top bit is OK */

}

The result is 0x00 for any byte with the top bit clear, 0xff for any byte with the top

bit set. This is the algorithm used in the ﬁle raid6int.uc.

For additional speed improvements, it is desirable to use any integer vector instruction
set that happens to be available on the machine, such as MMX or SSE-2 on x86, AltiVec
on PowerPC, etc. These instruction sets typically have quirks that may make them easier
or harder to use than the integer implementation, but usually easier. For example, the
MMX/SSE-2 instruction PCMPGTB conveniently implements the MASK() function when com-
paring against zero, and the PADDB instruction implements the shift and mask in the ﬁrst
line of the operations on vv when added with itself.

Note that none of this will avoid the arbitrary multiplications of equations 5 and 19.
Thus, in 2-disk-degraded mode, performance will be very slow. However, it is expected that
that will be a rare occurrence, and that performance will not matter signiﬁcantly in that
case.

3.1 Special notes on PowerPC AltiVec and x86 SSSE3

The Altivec SIMD vector instruction set for PowerPC has a special instruction, vperm,
which does a parallel table lookup using the bottom ﬁve bits of each byte in a vector.

This can be used to handle arbitrary scalar · vector multiplication (as in equations 5 and

19) quickly, by decomposing the vector.

This decomposition is simply a matter of observing that, from the distributive law:

V = Va + Vb

A · V = A · Va + A · Vb

For the decomposition to work, there can only be 32 possible values for each byte in Va
or Vb; the easiest such decomposition is simply Va being the low four bits and Vb being
the high four bits; since addition is XOR this is a valid decomposition, and there are only
16 possible values of each.

Thus, for each multiplication (i.e. value of A) we need to set up a pair of vector registers,
one which contains (A·{00}, A·{01}, A·{02}, ... A·{0f}) and one which contains (A·{00},
A · {10}, A · {20}, ... A · {f0}).

If these vectors are in v12 and v13 respectively, and v14 set up to contain ({04}, {04},

...), we can compute v1 ← A · v0 this way:

6

On most Altivec processors, this will execute in three cycles. Note that we don’t actually
need to mask the top bits for the ﬁrst vperm; since we repeat v12 twice we eﬀectively ignore
bit 4, and bits 5-7 are ignored by the hardware anyway.

The SSSE3 (Supplemental SSE3) extensions to the x86 instruction set includes a PSHUFB
instruction, which can be used in a similar way. PSHUFB uses bit 7 as a control bit, which
means that the lower half operation has to be masked; simply replicating the inputs will not
help. Furthermore, since no PSRAB instruction exists, one also has to mask the high half.
Thus, as above, with xmm14 having the scalar constant {0f}:

vsrb
v1, v0, v14
vperm v2, v12, v12, v0
vperm v1, v13, v13, v1
v1, v2, v1
vxor

xmm0, 4

movdqa xmm2, xmm0
psraw
movdqa xmm1, xmm12
movdqa xmm3, xmm13
xmm0, xmm14
pand
pand
xmm2, xmm14
pshufb xmm1, xmm0
pshufb xmm3, xmm2
xmm1, xmm3
pxor

4 Single-disk corruption recovery

It is possible to use the RAID-6 syndrome set to recover from a single disk corruption, as
opposed to one or two known failed drives (called erasures.)

This requires recomputation of the syndrome set on read. This can of course also be

done as a periodic integrity check, or as recovery if corruption is known or believed.

To consider the case of a single corrupt disk, we ﬁrst consider the case where the failed
disk (z) is one of the data drives (Dz). We will represent the corrupt data on that drive with
Xz. Obviously, the value z is unknown, although of course, by deﬁnition, 0 ≤ z < n ≤ 255.

We compute the standard syndrome set over the corrupt disk set:

P(cid:48) = D0 + D1 + . . . + Xz + . . . + Dn−1
Q(cid:48) = g0 · D0 + g1 · D1 + . . . + gz · Xz + . . . + gn−1 · Dn−1

It obviously follows that:

P(cid:63) = P + P(cid:48) = Dz + Xz
Q(cid:63) = Q + Q(cid:48) = gz · Dz + gz · Xz = gz · (Dz + Xz) = gz · P(cid:63)

By assumption, Xz (cid:54)= Dz and thus P(cid:63) (cid:54)= {00}. Furthermore, since gz (cid:54)= {00} for any z,

Q(cid:63) (cid:54)= {00}.

Thus it it valid to state:

(22)

(23)

(24)

(25)

(26)

Q(cid:63)/P(cid:63) = gz

7

Since 0 ≤ z < n ≤ 255, it then follows:

z = logg(Q(cid:63)/P(cid:63)) = logg Q(cid:63) (cid:9) logg P(cid:63)

(27)

... which will be a well-deﬁned relation for all possible values that ﬁt the required

assumptions.

As noted above, for the case of a corrupt data drive, P(cid:63) (cid:54)= {00}, and Q(cid:63) (cid:54)= {00}. The
other possible cases can be trivially shown to result in various combinations which involve
P(cid:63) and/or Q(cid:63) being zero:

or, equivalently:

No corruption
P drive corruption
Q drive corruption
Data drive corruption

P(cid:63)

Q(cid:63)

= {00} = {00}
(cid:54)= {00} = {00}
(cid:54)= {00}
= {00}
(cid:54)= {00}
(cid:54)= {00}

P(cid:48)

Q(cid:48)

P = P(cid:48) Q = Q(cid:48)
No corruption
P (cid:54)= P(cid:48) Q = Q(cid:48)
P drive corruption
P = P(cid:48) Q (cid:54)= Q(cid:48)
Q drive corruption
Data drive corruption P (cid:54)= P(cid:48) Q (cid:54)= Q(cid:48)

Obviously, for the cases of P or Q drive corruption, just replace the corrupt data with
the recomputed P(cid:48) or Q(cid:48), respectively. In the case of data drive corruption, once the faulty
drive has been identiﬁed, recover using the P drive in the same way as a one-disk erasure
failure.

It should be noted that although we have used scalar notation for the corrupt drive, data
corruption is actually detected on a byte by byte basis. Thus, the zeroness tests should be
done for each byte, and z in equation 27 really should be a vector result, z. It it, of course, a
quality of implementation issue whether or not it is possible to recover from multiple drives
having non-overlapping corruption in corresponding sectors or blocks.

Finally, as a word of caution it should be noted that RAID-6 by itself cannot (in the
general case) even detect, never mind recover from, dual-disk corruption. If two disks are
corrupt in the same byte positions, the above algorithm will (again, in the general case)
introduce additional data corruption by corrupting a third drive. However, the following
probabilistic patterns are likely to be indicative of such multidisk corruption, and a qual-
ity implementation should take appropriate action, such as aborting rather than further
corrupting data:

• z values inconsistent with the number of disks, for example z = 136 when n = 20.

• Inconsistent z values within a single hardware sector or block. This does not apply
to occasional bytes with no corruption (P(cid:63) = Q(cid:63) = {00}) – after all, even a standing
clock is correct once every 12 hours.

8

5 Beyond RAID-6

Reed-Solomon coding can be exploited further to allow for any combination of n data disks
plus m redundancy disks allowing for any m failures to be recovered. However, with in-
creasing amount of redundancy, the higher the overhead both in CPU time and I/O. The
Linux RAID-6 work has been focused on handling the case of m = 2 eﬃciently in order for
it to be practically useful.

An excellent paper on implementing arbitrarily complex recovery sets using Reed-Solomon

coding can be found at:

http://www.cs.utk.edu/~plank/plank/papers/CS-96-332.html

9

